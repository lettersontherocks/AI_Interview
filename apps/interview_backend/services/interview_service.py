"""é¢è¯•æœåŠ¡é€»è¾‘"""
import json
import uuid
from datetime import datetime
from typing import Optional, List, Dict
from sqlalchemy.orm import Session
from sqlalchemy.orm.attributes import flag_modified

from database.db import InterviewSession, InterviewReport, User
from models.schemas import (
    InterviewStartRequest, InterviewStartResponse,
    AnswerRequest, AnswerResponse, InterviewReport as InterviewReportSchema
)
from config import settings
from services.qwen_service import QwenService
from services.position_service import position_service
from services.knowledge_service import knowledge_service


class InterviewService:
    """é¢è¯•æœåŠ¡"""

    def __init__(self):
        # åˆå§‹åŒ– Qwen æœåŠ¡
        self.qwen_service = QwenService(api_key=settings.dashscope_api_key)

    def _call_llm(self, messages: List[dict], system: str = None, temperature: float = 0.8) -> str:
        """è°ƒç”¨å¤§æ¨¡å‹ APIï¼ˆä½¿ç”¨ Qwenï¼‰"""
        try:
            return self.qwen_service.chat(
                messages=messages,
                system=system,
                temperature=temperature,
                max_tokens=2000
            )
        except Exception as e:
            raise Exception(f"è°ƒç”¨ Qwen API å¤±è´¥: {str(e)}")

    def _auto_select_interviewer_style(self, round: str) -> str:
        """æ ¹æ®é¢è¯•è½®æ¬¡æ™ºèƒ½é€‰æ‹©é¢è¯•å®˜é£æ ¼"""
        import random

        # æ ¹æ®é¢è¯•è½®æ¬¡è®¾å®šå¯èƒ½çš„é£æ ¼ç»„åˆï¼Œæ¨¡æ‹ŸçœŸå®åœºæ™¯
        style_mapping = {
            "HRé¢": ["friendly", "mentor"],  # HRæ›´å€¾å‘å‹å¥½å’Œå¼•å¯¼
            "æŠ€æœ¯ä¸€é¢": ["friendly", "professional"],  # åŸºç¡€é¢è¯•ï¼Œå‹å¥½æˆ–ä¸“ä¸š
            "æŠ€æœ¯äºŒé¢": ["professional", "challenging"],  # æ·±åº¦é¢è¯•ï¼Œä¸“ä¸šæˆ–æœ‰å‹åŠ›
            "æ€»ç›‘é¢": ["professional", "challenging", "mentor"]  # é«˜å±‚é¢è¯•ï¼Œå„ç§å¯èƒ½
        }

        candidates = style_mapping.get(round, ["friendly", "professional"])
        selected = random.choice(candidates)

        print(f"[é¢è¯•å®˜åˆ†é…] {round} -> è‡ªåŠ¨é€‰æ‹©: {selected}")
        return selected

    def _extract_tech_keywords(self, answer: str) -> str:
        """ä»å€™é€‰äººå›ç­”ä¸­æå–æŠ€æœ¯å…³é”®è¯

        Args:
            answer: å€™é€‰äººå›ç­”

        Returns:
            æå–çš„å…³é”®è¯å­—ç¬¦ä¸²
        """
        # ç®€å•å®ç°ï¼šæå–å¸¸è§æŠ€æœ¯è¯æ±‡
        # å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ NLP æ–¹æ³•ï¼Œä½†è¿™é‡Œä¿æŒç®€å•
        import re

        # å¸¸è§æŠ€æœ¯è¯æ±‡æ¨¡å¼ï¼ˆä¸­è‹±æ–‡ï¼‰
        tech_patterns = [
            r'\b[A-Z][a-z]+(?:[A-Z][a-z]+)*\b',  # é©¼å³°å‘½åï¼ˆå¦‚ï¼šArrayList, HashMapï¼‰
            r'\b[A-Z]{2,}\b',  # å…¨å¤§å†™ç¼©å†™ï¼ˆå¦‚ï¼šAPI, HTTP, SQLï¼‰
            r'\b(?:Python|Java|JavaScript|React|Vue|Django|Flask|Redis|MySQL|MongoDB|Docker|Kubernetes|Git)\b',  # å¸¸è§æŠ€æœ¯æ ˆ
            r'[\u4e00-\u9fa5]{2,}(?:ç®—æ³•|æ¨¡å¼|åè®®|æ¡†æ¶|åº“|æ–¹æ³•|å‡½æ•°|ç±»|æ¥å£)',  # ä¸­æ–‡æŠ€æœ¯è¯
        ]

        keywords = set()
        for pattern in tech_patterns:
            matches = re.findall(pattern, answer)
            keywords.update(matches)

        # é™åˆ¶å…³é”®è¯æ•°é‡ï¼Œé¿å…æŸ¥è¯¢è¿‡é•¿
        keywords_list = list(keywords)[:5]
        return " ".join(keywords_list) if keywords_list else ""

    def _get_interviewer_style(self, style: str = "friendly") -> dict:
        """è·å–é¢è¯•å®˜é£æ ¼é…ç½®"""
        styles = {
            "friendly": {
                "name": "å‹å¥½å‹",
                "description": "æ¸©å’Œå‹å–„ï¼Œé¼“åŠ±æ€§å¼ºï¼Œé€‚åˆç¼“è§£ç´§å¼ ",
                "personality": "ä½ æ˜¯ä¸€ä½æ¸©å’Œå‹å–„çš„é¢è¯•å®˜ï¼Œå–„äºé¼“åŠ±å€™é€‰äººï¼Œè¥é€ è½»æ¾æ°›å›´ã€‚",
                "feedback_examples": ["å¾ˆå¥½ï¼", "ä¸é”™çš„å›ç­”", "æˆ‘æ˜ç™½äº†", "å—¯ï¼Œç»§ç»­è¯´", "å¾ˆæœ‰æ„æ€"]
            },
            "professional": {
                "name": "ä¸“ä¸šå‹",
                "description": "ä¸¥è°¨ä¸“ä¸šï¼Œæ³¨é‡æ·±åº¦ï¼Œè¿½æ±‚æŠ€æœ¯ç»†èŠ‚",
                "personality": "ä½ æ˜¯ä¸€ä½ä¸¥è°¨ä¸“ä¸šçš„æŠ€æœ¯ä¸“å®¶ï¼Œæ³¨é‡æŠ€æœ¯æ·±åº¦å’Œç»†èŠ‚ï¼Œå–„äºæ·±å…¥è¿½é—®ã€‚",
                "feedback_examples": ["å¥½çš„", "æ˜ç™½", "ç»§ç»­", "å—¯", "æˆ‘äº†è§£äº†"]
            },
            "challenging": {
                "name": "æŒ‘æˆ˜å‹",
                "description": "æœ‰å‹åŠ›æ„Ÿï¼Œå–„äºæå‡ºå°–é”é—®é¢˜",
                "personality": "ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„é«˜çº§é¢è¯•å®˜ï¼Œå–„äºé€šè¿‡æŒ‘æˆ˜æ€§é—®é¢˜è€ƒå¯Ÿå€™é€‰äººçš„åº”å˜èƒ½åŠ›å’Œæ·±åº¦æ€è€ƒã€‚",
                "feedback_examples": ["æœ‰æ„æ€", "è¿™ä¸ªç­”æ¡ˆè¿˜ä¸å¤Ÿæ·±å…¥", "ç»§ç»­", "ç„¶åå‘¢", "è¿˜æœ‰å—"]
            },
            "mentor": {
                "name": "å¯¼å¸ˆå‹",
                "description": "åƒå¯¼å¸ˆä¸€æ ·å¼•å¯¼ï¼Œå–„äºå¯å‘æ€è€ƒ",
                "personality": "ä½ æ˜¯ä¸€ä½åƒå¯¼å¸ˆä¸€æ ·çš„é¢è¯•å®˜ï¼Œå–„äºé€šè¿‡å¼•å¯¼å’Œå¯å‘å¸®åŠ©å€™é€‰äººå±•ç°æœ€ä½³çŠ¶æ€ã€‚",
                "feedback_examples": ["å¾ˆå¥½ï¼Œæˆ‘ä»¬æ¢ä¸ªè§’åº¦æƒ³æƒ³", "ä¸é”™çš„æ€è·¯", "æ˜ç™½äº†", "æœ‰é“ç†", "ç»§ç»­æ·±å…¥è¯´è¯´"]
            }
        }
        return styles.get(style, styles["friendly"])

    def get_all_interviewer_styles(self) -> List[Dict]:
        """è·å–æ‰€æœ‰é¢è¯•å®˜é£æ ¼ï¼ˆä¾›å‰ç«¯é€‰æ‹©ï¼‰"""
        styles_config = {
            "friendly": {
                "name": "å‹å¥½å‹",
                "description": "æ¸©å’Œå‹å–„ï¼Œé¼“åŠ±æ€§å¼ºï¼Œé€‚åˆç¼“è§£ç´§å¼ ",
                "icon": "ğŸ˜Š"
            },
            "professional": {
                "name": "ä¸“ä¸šå‹",
                "description": "ä¸¥è°¨ä¸“ä¸šï¼Œæ³¨é‡æ·±åº¦ï¼Œè¿½æ±‚æŠ€æœ¯ç»†èŠ‚",
                "icon": "ğŸ’¼"
            },
            "challenging": {
                "name": "æŒ‘æˆ˜å‹",
                "description": "æœ‰å‹åŠ›æ„Ÿï¼Œå–„äºæå‡ºå°–é”é—®é¢˜",
                "icon": "ğŸ”¥"
            },
            "mentor": {
                "name": "å¯¼å¸ˆå‹",
                "description": "åƒå¯¼å¸ˆä¸€æ ·å¼•å¯¼ï¼Œå–„äºå¯å‘æ€è€ƒ",
                "icon": "ğŸ“"
            }
        }

        result = []
        for style_id, config in styles_config.items():
            result.append({
                "id": style_id,
                "name": config["name"],
                "description": config["description"],
                "icon": config["icon"]
            })

        return result

    def get_recommended_style(self, round: str) -> str:
        """æ ¹æ®é¢è¯•è½®æ¬¡è·å–æ¨èçš„é¢è¯•å®˜é£æ ¼"""
        # æ¨èæ˜ å°„ï¼ˆåŸºäºä¹‹å‰çš„æ™ºèƒ½åˆ†é…é€»è¾‘ï¼‰
        recommendations = {
            "æŠ€æœ¯ä¸€é¢": "friendly",
            "æŠ€æœ¯äºŒé¢": "professional",
            "æŠ€æœ¯ä¸‰é¢": "challenging",
            "HRé¢": "friendly",
            "æ€»ç›‘é¢": "challenging",
            "ç»ˆé¢": "professional"
        }
        return recommendations.get(round, "friendly")

    def _get_system_prompt(self, position: str, round: str, interviewer_style: str = "friendly", resume: Optional[str] = None) -> str:
        """ç”Ÿæˆç³»ç»Ÿæç¤ºè¯"""
        style_config = self._get_interviewer_style(interviewer_style)

        base_prompt = f"""ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„{position}é¢è¯•å®˜ï¼Œæ­£åœ¨è¿›è¡Œ{round}ã€‚

ã€é¢è¯•å®˜é£æ ¼ã€‘
{style_config['personality']}

ã€é‡è¦äº¤äº’è¦æ±‚ã€‘
1. åœ¨å€™é€‰äººå›ç­”åï¼Œä½ å¿…é¡»å…ˆç»™å‡ºç®€çŸ­çš„äº’åŠ¨åé¦ˆï¼ˆå¦‚ï¼š"{style_config['feedback_examples'][0]}"ã€"{style_config['feedback_examples'][1]}"ç­‰ï¼‰ï¼Œè®©å¯¹è¯æ›´è‡ªç„¶æµç•…
2. äº’åŠ¨åé¦ˆè¦ç®€çŸ­ï¼ˆ1-5ä¸ªå­—ï¼‰ï¼Œä¸è¦è¿‡é•¿ï¼Œæ¨¡æ‹ŸçœŸå®é¢è¯•çš„èŠ‚å¥
3. åé¦ˆåå†è¿›è¡Œè¯„åˆ†å’Œæå‡ºä¸‹ä¸€ä¸ªé—®é¢˜

ã€é¢è¯•è¦æ±‚ã€‘
1. æé—®è¦ä¸“ä¸šã€æœ‰é’ˆå¯¹æ€§ï¼Œæ ¹æ®å€™é€‰äººçš„å›ç­”æ·±å…¥è¿½é—®
2. é—®é¢˜éš¾åº¦è¦å¾ªåºæ¸è¿›ï¼Œä»åŸºç¡€åˆ°è¿›é˜¶
3. å…³æ³¨å€™é€‰äººçš„æŠ€æœ¯æ·±åº¦ã€é¡¹ç›®ç»éªŒã€é€»è¾‘æ€ç»´å’Œæ²Ÿé€šèƒ½åŠ›
4. æ¯æ¬¡åªé—®ä¸€ä¸ªé—®é¢˜ï¼Œç­‰å¾…å€™é€‰äººå›ç­”åå†ç»§ç»­
5. æ ¹æ®å€™é€‰äººçš„å›ç­”ç»™å‡ºå³æ—¶è¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰å’Œæ”¹è¿›æç¤º

ã€é¢è¯•æµç¨‹ã€‘
- å¼€åœºï¼šç®€å•è‡ªæˆ‘ä»‹ç»å’Œçƒ­èº«é—®é¢˜ï¼ˆ1-2ä¸ªï¼‰
- åŸºç¡€çŸ¥è¯†ï¼šè€ƒå¯Ÿæ ¸å¿ƒæŠ€æœ¯æ ˆï¼ˆ2-3ä¸ªï¼‰
- æ·±å…¥æ¢è®¨ï¼šé¡¹ç›®ç»éªŒå’Œè§£å†³æ–¹æ¡ˆï¼ˆ2-3ä¸ªï¼‰
- åœºæ™¯é—®é¢˜ï¼šå®é™…é—®é¢˜è§£å†³èƒ½åŠ›ï¼ˆ1-2ä¸ªï¼‰
- æ”¶å°¾ï¼šå€™é€‰äººæé—®ç¯èŠ‚

æ€»è®¡8-10ä¸ªé—®é¢˜ï¼Œæ§åˆ¶åœ¨15-20åˆ†é’Ÿå†…ã€‚"""

        if resume:
            base_prompt += f"\n\nã€å€™é€‰äººç®€å†ã€‘\n{resume}\n\nè¯·æ ¹æ®ç®€å†å†…å®¹é’ˆå¯¹æ€§æé—®ã€‚"

        return base_prompt

    def _get_position_questions(self, position_id: str, round_name: str = None) -> tuple[str, List[Dict]]:
        """è·å–å²—ä½ç›¸å…³é—®é¢˜æç¤ºå’ŒçŸ¥è¯†åº“å‚è€ƒé¢˜ç›®

        Returns:
            (æç¤ºæ–‡æœ¬, å‚è€ƒé¢˜ç›®åˆ—è¡¨)
        """
        # ä»å²—ä½æœåŠ¡è·å–å…³é”®è¯
        keywords = position_service.get_position_keywords(position_id)
        position_info = position_service.get_position_by_id(position_id)

        if not position_info:
            return "", []

        # æ„å»ºé—®é¢˜æç¤º
        keywords_str = "ã€".join(keywords) if keywords else "ç›¸å…³æŠ€èƒ½"
        full_name = position_service.get_position_full_name(position_id)

        # ä»çŸ¥è¯†åº“è·å–å‚è€ƒé¢˜ç›®ï¼ˆè·å–è¾ƒå¤šé¢˜ç›®ä½œä¸ºé¢˜åº“æ± ï¼‰
        reference_questions = []
        try:
            reference_questions = knowledge_service.search_by_position(
                position=full_name,
                limit=50  # è·å–50æ¡ä½œä¸ºå‚è€ƒæ± 
            )
            print(f"[çŸ¥è¯†åº“] ä¸º {full_name} è·å–äº† {len(reference_questions)} æ¡å‚è€ƒé¢˜ç›®")
        except Exception as e:
            print(f"[çŸ¥è¯†åº“] è·å–å‚è€ƒé¢˜ç›®å¤±è´¥: {e}")

        hint = f"é‡ç‚¹è€ƒå¯Ÿï¼š{keywords_str}ï¼ˆé’ˆå¯¹{full_name}å²—ä½ï¼‰"
        return hint, reference_questions

    def _generate_interview_plan(self, position: str, round: str, resume: Optional[str] = None, reference_questions: List[Dict] = None) -> dict:
        """ç”ŸæˆåŠ¨æ€é¢è¯•è®¡åˆ’

        Args:
            position: å²—ä½åç§°
            round: é¢è¯•è½®æ¬¡
            resume: ç®€å†ï¼ˆå¯é€‰ï¼‰
            reference_questions: çŸ¥è¯†åº“å‚è€ƒé¢˜ç›®ï¼ˆå¯é€‰ï¼‰
        """
        # æ„å»ºçŸ¥è¯†åº“å‚è€ƒä¿¡æ¯
        knowledge_context = ""
        if reference_questions:
            # éšæœºé€‰æ‹©10æ¡å‚è€ƒé¢˜ç›®å±•ç¤ºç»™LLM
            import random
            sample_questions = random.sample(reference_questions, min(10, len(reference_questions)))
            questions_preview = "\n".join([f"- {q.get('question', '')}" for q in sample_questions])
            knowledge_context = f"\n\nã€çŸ¥è¯†åº“å‚è€ƒé¢˜ç›®ç¤ºä¾‹ã€‘ï¼ˆä»…ä¾›å‚è€ƒï¼Œä¸è¦ç…§æ¬ï¼Œè¦ç»“åˆå€™é€‰äººæƒ…å†µæ”¹ç¼–å’Œå»¶ä¼¸ï¼‰ï¼š\n{questions_preview}"

        messages = [{
            "role": "user",
            "content": f"""ä½œä¸º{position}çš„{round}é¢è¯•å®˜ï¼Œè¯·ä¸ºæœ¬æ¬¡é¢è¯•åˆ¶å®šä¸€ä¸ªçµæ´»çš„é¢è¯•è®¡åˆ’ã€‚

{"å€™é€‰äººç®€å†ï¼š" + resume if resume else "æ— ç®€å†ä¿¡æ¯"}
{knowledge_context}

è¯·è®¾è®¡é¢è¯•ä¸»é¢˜å’Œå¤§è‡´æ–¹å‘ï¼Œä½†ä¿æŒçµæ´»æ€§ä»¥ä¾¿æ ¹æ®å€™é€‰äººè¡¨ç°è°ƒæ•´ã€‚

ã€é‡è¦ã€‘å¦‚æœæœ‰çŸ¥è¯†åº“å‚è€ƒé¢˜ç›®ï¼Œè¯·ç†è§£å…¶è€ƒå¯Ÿæ–¹å‘å’ŒçŸ¥è¯†ç‚¹ï¼Œä½†ä¸è¦ç›´æ¥ç…§æ¬ï¼Œè¦ï¼š
1. æ ¹æ®å€™é€‰äººç®€å†ä¸ªæ€§åŒ–è°ƒæ•´
2. ç”¨è‡ªå·±çš„æ–¹å¼é‡æ–°ç»„ç»‡é—®é¢˜
3. ç»“åˆå®é™…é¡¹ç›®åœºæ™¯å»¶ä¼¸

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºé¢è¯•è®¡åˆ’ï¼š
{{
    "topics": ["å¼€åœºçƒ­èº«", "åŸºç¡€æŠ€èƒ½", "é¡¹ç›®ç»éªŒ", "æ·±å…¥æŠ€æœ¯", "åœºæ™¯é—®é¢˜"],
    "topic_descriptions": {{
        "å¼€åœºçƒ­èº«": "ç®€å•ä»‹ç»ï¼Œç¼“è§£ç´§å¼ ",
        "åŸºç¡€æŠ€èƒ½": "è€ƒå¯Ÿæ ¸å¿ƒæŠ€æœ¯æ ˆåŸºç¡€çŸ¥è¯†",
        "é¡¹ç›®ç»éªŒ": "äº†è§£å®é™…é¡¹ç›®ç»éªŒå’Œæˆæœ",
        "æ·±å…¥æŠ€æœ¯": "æ·±å…¥æ¢è®¨æŠ€æœ¯ç»†èŠ‚å’ŒåŸç†",
        "åœºæ™¯é—®é¢˜": "è€ƒå¯Ÿå®é™…é—®é¢˜è§£å†³èƒ½åŠ›"
    }},
    "estimated_duration": "15-25åˆ†é’Ÿ",
    "flexibility_note": "æ ¹æ®å€™é€‰äººå›ç­”è´¨é‡åŠ¨æ€è°ƒæ•´æ·±åº¦å’Œå¹¿åº¦"
}}"""
        }]

        response_text = self._call_llm(messages, temperature=0.7)

        try:
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                plan = json.loads(json_match.group())
            else:
                plan = json.loads(response_text)

            # æ·»åŠ è¿è¡Œæ—¶çŠ¶æ€
            plan["current_topic_index"] = 0
            plan["completed_topics"] = []
            plan["should_continue"] = True

            return plan
        except Exception as e:
            print(f"[ERROR] ç”Ÿæˆé¢è¯•è®¡åˆ’å¤±è´¥: {e}")
            # è¿”å›é»˜è®¤è®¡åˆ’
            return {
                "topics": ["å¼€åœºçƒ­èº«", "æ ¸å¿ƒæŠ€èƒ½", "é¡¹ç›®ç»éªŒ", "ç»¼åˆè¯„ä¼°"],
                "topic_descriptions": {
                    "å¼€åœºçƒ­èº«": "ç®€å•ä»‹ç»",
                    "æ ¸å¿ƒæŠ€èƒ½": "æŠ€æœ¯åŸºç¡€",
                    "é¡¹ç›®ç»éªŒ": "å®è·µç»éªŒ",
                    "ç»¼åˆè¯„ä¼°": "ç»¼åˆèƒ½åŠ›"
                },
                "current_topic_index": 0,
                "completed_topics": [],
                "should_continue": True
            }

    def start_interview(self, request: InterviewStartRequest, db: Session) -> InterviewStartResponse:
        """å¼€å§‹é¢è¯•"""
        # ç”Ÿæˆä¼šè¯ID
        session_id = f"session_{uuid.uuid4().hex[:16]}"

        # è·å–é¢è¯•å®˜é£æ ¼ï¼ˆä¼˜å…ˆä½¿ç”¨ç”¨æˆ·é€‰æ‹©ï¼Œå¦åˆ™æ™ºèƒ½æ¨èï¼‰
        interviewer_style = request.interviewer_style
        if not interviewer_style:
            interviewer_style = self._auto_select_interviewer_style(request.round)
            print(f"[é¢è¯•å®˜åˆ†é…] ç”¨æˆ·æœªé€‰æ‹©ï¼Œè‡ªåŠ¨æ¨è: {interviewer_style}")
        else:
            print(f"[é¢è¯•å®˜åˆ†é…] ç”¨æˆ·é€‰æ‹©: {interviewer_style}")

        # è·å–å²—ä½å®Œæ•´åç§°
        position_full_name = position_service.get_position_full_name(request.position_id)

        # è·å–çŸ¥è¯†åº“å‚è€ƒé¢˜ç›®
        questions_guide, reference_questions = self._get_position_questions(request.position_id, request.round)

        # ç”Ÿæˆé¢è¯•è®¡åˆ’ï¼ˆä¼ å…¥å‚è€ƒé¢˜ç›®ï¼‰
        interview_plan = self._generate_interview_plan(position_full_name, request.round, request.resume, reference_questions)
        print(f"[é¢è¯•è®¡åˆ’] {interview_plan}")

        # ç”Ÿæˆç³»ç»Ÿæç¤ºè¯ï¼ˆä½¿ç”¨é¢è¯•å®˜é£æ ¼ï¼‰
        system_prompt = self._get_system_prompt(position_full_name, request.round, interviewer_style, request.resume)

        # è·å–å½“å‰ä¸»é¢˜
        current_topic = interview_plan["topics"][0] if interview_plan["topics"] else "å¼€åœº"
        topic_desc = interview_plan.get("topic_descriptions", {}).get(current_topic, "")

        # æ„å»ºçŸ¥è¯†åº“å‚è€ƒï¼ˆä»…ç”¨äºå¼€åœºé˜¶æ®µï¼Œé€‰æ‹©ç®€å•é¢˜ç›®ï¼‰
        knowledge_hint = ""
        if reference_questions:
            # éšæœºé€‰æ‹©3æ¡ç®€å•çš„å‚è€ƒé¢˜ç›®
            import random
            sample = random.sample(reference_questions, min(3, len(reference_questions)))
            sample_text = "\n".join([f"- {q.get('question', '')}" for q in sample])
            knowledge_hint = f"\n\nã€å‚è€ƒæ–¹å‘ã€‘ï¼ˆä¸è¦ç…§æ¬ï¼Œè¦è‡ªç„¶æ”¹ç¼–ï¼‰ï¼š\n{sample_text}"

        # ç”Ÿæˆå¼€åœºé—®é¢˜
        messages = [
            {
                "role": "user",
                "content": f"""ç°åœ¨å¼€å§‹{position_full_name}çš„{request.round}ã€‚

{questions_guide}

å½“å‰ä¸»é¢˜ï¼š{current_topic} - {topic_desc}
{knowledge_hint}

è¯·æå‡ºç¬¬ä¸€ä¸ªå¼€åœºé—®é¢˜ï¼Œè¦æ±‚ï¼š
1. å‹å¥½ã€ä¸“ä¸šçš„å¼€åœºç™½
2. ä¸€ä¸ªç®€å•çš„çƒ­èº«é—®é¢˜
3. è®©å€™é€‰äººæ”¾æ¾å¹¶è¿›å…¥çŠ¶æ€
4. å¦‚æœæœ‰å‚è€ƒé¢˜ç›®ï¼Œç†è§£å…¶è€ƒå¯Ÿç‚¹ï¼Œä½†è¦ç”¨è‡ªå·±çš„æ–¹å¼è¡¨è¾¾

ç›´æ¥è¾“å‡ºé—®é¢˜ï¼Œä¸è¦è¾“å‡ºå…¶ä»–å†…å®¹ã€‚"""
            }
        ]

        first_question = self._call_llm(messages, system=system_prompt, temperature=0.7)

        # å°†å‚è€ƒé¢˜ç›®ä¿å­˜åˆ°é¢è¯•è®¡åˆ’ä¸­
        interview_plan["reference_questions"] = reference_questions

        # åˆ›å»ºä¼šè¯è®°å½•
        session = InterviewSession(
            session_id=session_id,
            user_id=request.user_id,
            position=position_full_name,  # ä¿å­˜å®Œæ•´å²—ä½åç§°
            round=request.round,
            resume=request.resume,
            interview_plan=interview_plan,  # ä¿å­˜é¢è¯•è®¡åˆ’ï¼ˆåŒ…å«å‚è€ƒé¢˜ç›®ï¼‰
            current_question=first_question,
            question_count=1,
            transcript=[
                {
                    "role": "interviewer",
                    "content": first_question,
                    "timestamp": datetime.utcnow().isoformat(),
                    "question_number": 1,
                    "style": interviewer_style,  # ä¿å­˜é¢è¯•å®˜é£æ ¼
                    "topic": current_topic  # ä¿å­˜å½“å‰ä¸»é¢˜
                }
            ]
        )
        db.add(session)
        db.commit()

        return InterviewStartResponse(
            session_id=session_id,
            question=first_question,
            question_type="å¼€åœº"
        )

    def process_answer(self, request: AnswerRequest, db: Session) -> AnswerResponse:
        """å¤„ç†å€™é€‰äººå›ç­”"""
        # è·å–ä¼šè¯
        session = db.query(InterviewSession).filter(
            InterviewSession.session_id == request.session_id
        ).first()

        if not session:
            raise ValueError("ä¼šè¯ä¸å­˜åœ¨")

        if session.is_finished:
            raise ValueError("é¢è¯•å·²ç»“æŸ")

        # è®°å½•å€™é€‰äººå›ç­”
        session.transcript.append({
            "role": "candidate",
            "content": request.answer,
            "timestamp": datetime.utcnow().isoformat(),
            "question_number": session.question_count
        })
        flag_modified(session, "transcript")

        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦ä¸»åŠ¨ç»“æŸé¢è¯•
        if request.finish_interview:
            print(f"[é¢è¯•ç»“æŸ] ç”¨æˆ·ä¸»åŠ¨ç»“æŸé¢è¯•")
            session.is_finished = True
            session.finished_at = datetime.utcnow()
            db.commit()

            return AnswerResponse(
                next_question=None,
                instant_score=None,
                hint="æ„Ÿè°¢æ‚¨å‚åŠ æœ¬æ¬¡é¢è¯•ï¼ŒæŠ¥å‘Šå·²ç”Ÿæˆ",
                is_finished=True
            )

        # æ„å»ºå¯¹è¯å†å²
        messages = []
        for item in session.transcript[-6:]:  # æœ€è¿‘3è½®å¯¹è¯
            role = "assistant" if item["role"] == "interviewer" else "user"
            messages.append({"role": role, "content": item["content"]})

        # è·å–é¢è¯•è®¡åˆ’
        interview_plan = session.interview_plan or {}
        topics = interview_plan.get("topics", [])
        current_topic_index = interview_plan.get("current_topic_index", 0)
        completed_topics = interview_plan.get("completed_topics", [])

        # åˆ¤æ–­æ˜¯å¦å®Œæˆæ‰€æœ‰ä¸»é¢˜
        all_topics_completed = current_topic_index >= len(topics)

        if not all_topics_completed:
            # ç»§ç»­é¢è¯•
            # ç”Ÿæˆä¸‹ä¸€ä¸ªé—®é¢˜ï¼ˆä½¿ç”¨ä¼šè¯ä¸­ä¿å­˜çš„é¢è¯•å®˜é£æ ¼ï¼Œé»˜è®¤ä¸º friendlyï¼‰
            interviewer_style = session.transcript[0].get("style", "friendly") if session.transcript else "friendly"
            system_prompt = self._get_system_prompt(session.position, session.round, interviewer_style, session.resume)

            # è·å–å½“å‰ä¸»é¢˜ä¿¡æ¯
            current_topic = topics[current_topic_index] if current_topic_index < len(topics) else "ç»¼åˆè¯„ä¼°"
            topic_desc = interview_plan.get("topic_descriptions", {}).get(current_topic, "")

            # åŠ¨æ€çŸ¥è¯†åº“æ£€ç´¢ï¼šæ ¹æ®å€™é€‰äººå›ç­”æå–å…³é”®è¯å¹¶æœç´¢ç›¸å…³é¢˜ç›®
            dynamic_references = []
            try:
                # ç®€å•å…³é”®è¯æå–ï¼ˆä»å›ç­”ä¸­æå–æŠ€æœ¯è¯æ±‡ï¼‰
                answer_keywords = self._extract_tech_keywords(request.answer)
                if answer_keywords:
                    print(f"[çŸ¥è¯†åº“] ä»å›ç­”ä¸­æå–å…³é”®è¯: {answer_keywords}")
                    dynamic_references = knowledge_service.search_related_questions(
                        keywords=answer_keywords,
                        position=session.position,
                        limit=5
                    )
                    print(f"[çŸ¥è¯†åº“] åŠ¨æ€æ£€ç´¢åˆ° {len(dynamic_references)} æ¡ç›¸å…³é¢˜ç›®")
            except Exception as e:
                print(f"[çŸ¥è¯†åº“] åŠ¨æ€æ£€ç´¢å¤±è´¥: {e}")

            # æ„å»ºçŸ¥è¯†åº“å‚è€ƒæç¤º
            knowledge_hint = ""
            if dynamic_references:
                # ä½¿ç”¨åŠ¨æ€æ£€ç´¢ç»“æœ
                ref_text = "\n".join([f"- {q.get('question', '')}" for q in dynamic_references[:3]])
                knowledge_hint = f"\n\nã€ç›¸å…³å‚è€ƒé¢˜ç›®ã€‘ï¼ˆå¯ä½œä¸ºè¿½é—®æ–¹å‘ï¼Œä½†è¦è‡ªç„¶å»¶ä¼¸ï¼Œä¸è¦ç…§æ¬ï¼‰ï¼š\n{ref_text}"
            else:
                # ä½¿ç”¨åˆå§‹å‚è€ƒé¢˜åº“
                reference_questions = interview_plan.get("reference_questions", [])
                if reference_questions:
                    import random
                    sample = random.sample(reference_questions, min(3, len(reference_questions)))
                    ref_text = "\n".join([f"- {q.get('question', '')}" for q in sample])
                    knowledge_hint = f"\n\nã€å‚è€ƒé¢˜åº“ã€‘ï¼ˆå¯ä½œä¸ºæé—®æ–¹å‘ï¼‰ï¼š\n{ref_text}"

            messages.append({
                "role": "user",
                "content": f"""å€™é€‰äººå·²å›ç­”é—®é¢˜{session.question_count}ã€‚

ã€é¢è¯•è®¡åˆ’çŠ¶æ€ã€‘
- å½“å‰ä¸»é¢˜ï¼š{current_topic} - {topic_desc}
- å·²å®Œæˆä¸»é¢˜ï¼š{', '.join(completed_topics) if completed_topics else 'æ— '}
- å‰©ä½™ä¸»é¢˜ï¼š{', '.join(topics[current_topic_index+1:]) if current_topic_index+1 < len(topics) else 'æ— '}
{knowledge_hint}

ã€é‡è¦ã€‘è¯·ä¸¥æ ¼æŒ‰ç…§ä½ çš„é¢è¯•å®˜é£æ ¼è¿›è¡Œäº’åŠ¨ï¼

è¯·æ‰§è¡Œä»¥ä¸‹ä»»åŠ¡ï¼š
1. å…ˆç»™å‡ºç®€çŸ­çš„äº’åŠ¨åé¦ˆï¼ˆ2-8ä¸ªå­—ï¼Œå¦‚ï¼š"å¥½çš„"ã€"æ˜ç™½äº†"ã€"ä¸é”™"ç­‰ï¼‰ï¼Œè®©å¯¹è¯æ›´è‡ªç„¶
2. å¯¹å€™é€‰äººçš„å›ç­”è¿›è¡Œè¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰
3. ç»™å‡ºæ”¹è¿›æç¤ºï¼ˆ1-2å¥è¯ï¼ŒæŒ‡å‡ºå¯ä»¥æ”¹è¿›çš„åœ°æ–¹ï¼‰
4. **å†³å®šä¸‹ä¸€æ­¥åŠ¨ä½œ**ï¼š
   - å¦‚æœå€™é€‰äººå›ç­”å€¼å¾—æ·±å…¥æ¢è®¨ï¼Œå¯ä»¥é€‰æ‹©"å»¶ä¼¸è¿½é—®"ï¼ˆfollow_upï¼‰
   - å¦‚æœå€™é€‰äººå›ç­”å·²ç»è¶³å¤Ÿï¼Œé€‰æ‹©"è¿›å…¥ä¸‹ä¸€ä¸ªé—®é¢˜"ï¼ˆnext_topicï¼‰

ã€å»¶ä¼¸è¿½é—®çš„åœºæ™¯ã€‘ï¼ˆå¯é€‰ï¼Œä¸æ˜¯å¿…é¡»ï¼‰ï¼š
- å€™é€‰äººæåˆ°äº†æœ‰è¶£çš„æŠ€æœ¯ç»†èŠ‚ï¼Œå€¼å¾—æ·±æŒ–
- å›ç­”ä¸å¤Ÿå…·ä½“ï¼Œéœ€è¦è¿½é—®å®ç°æ–¹å¼
- å‘ç°äº†æ½œåœ¨çš„çŸ¥è¯†ç›²åŒºï¼Œæƒ³è¦ç¡®è®¤
- å€™é€‰äººè¡¨ç°å‡ºè‰²ï¼Œæƒ³è¦æŒ‘æˆ˜æ›´é«˜éš¾åº¦

ã€è¿›å…¥ä¸‹ä¸€ä¸ªé—®é¢˜çš„åœºæ™¯ã€‘ï¼š
- å½“å‰ä¸»é¢˜å·²ç»è€ƒå¯Ÿå……åˆ†
- å€™é€‰äººå›ç­”æ¸…æ™°å®Œæ•´
- éœ€è¦æ¨è¿›é¢è¯•è¿›åº¦

è¯·æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
{{
    "feedback": "å¥½çš„",
    "score": 8.5,
    "hint": "å›ç­”ä¸é”™ï¼Œä½†å¯ä»¥æ›´æ·±å…¥æ¢è®¨å…·ä½“çš„å®ç°ç»†èŠ‚",
    "action": "follow_up",  // æˆ– "next_topic"
    "next_question": "é—®é¢˜å†…å®¹",
    "topic_completed": false  // å½“å‰ä¸»é¢˜æ˜¯å¦å·²å®Œæˆï¼ˆå¦‚æœactionæ˜¯next_topicï¼Œè®¾ä¸ºtrueï¼‰
}}"""
            })

            response_text = self._call_llm(messages, system=system_prompt, temperature=0.8)
            print(f"[DEBUG] Qwen åŸå§‹å“åº”: {response_text}")

            # è§£æå“åº”
            try:
                # å°è¯•æå–JSON
                import re
                json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
                if json_match:
                    response_data = json.loads(json_match.group())
                else:
                    response_data = json.loads(response_text)

                print(f"[DEBUG] è§£æåçš„æ•°æ®: {response_data}")
                feedback = response_data.get("feedback", "å¥½çš„")
                instant_score = response_data.get("score", 7.0)
                hint = response_data.get("hint", "")
                next_question = response_data.get("next_question", "")
                action = response_data.get("action", "next_topic")  # follow_up æˆ– next_topic
                topic_completed = response_data.get("topic_completed", False)

                print(f"[DEBUG] feedback={feedback}, score={instant_score}, action={action}, topic_completed={topic_completed}")
            except Exception as e:
                # å¦‚æœè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼
                print(f"[DEBUG] JSONè§£æå¤±è´¥: {e}")
                feedback = "å¥½çš„"
                instant_score = 7.0
                hint = ""
                next_question = response_text
                action = "next_topic"
                topic_completed = False

            # æ›´æ–°æœ€åä¸€æ¡å€™é€‰äººå›ç­”çš„è¯„åˆ†å’Œåé¦ˆ
            session.transcript[-1]["score"] = instant_score
            session.transcript[-1]["hint"] = hint
            session.transcript[-1]["feedback"] = feedback

            # æ›´æ–°é¢è¯•è®¡åˆ’çŠ¶æ€
            if topic_completed and action == "next_topic":
                # å½“å‰ä¸»é¢˜å®Œæˆï¼Œç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªä¸»é¢˜
                if current_topic not in completed_topics:
                    completed_topics.append(current_topic)
                interview_plan["current_topic_index"] = current_topic_index + 1
                interview_plan["completed_topics"] = completed_topics

                # è·å–æ–°ä¸»é¢˜
                new_topic_index = interview_plan["current_topic_index"]
                if new_topic_index < len(topics):
                    new_topic = topics[new_topic_index]
                    print(f"[é¢è¯•è¿›åº¦] å®Œæˆä¸»é¢˜ï¼š{current_topic}ï¼Œè¿›å…¥æ–°ä¸»é¢˜ï¼š{new_topic}")
                else:
                    print(f"[é¢è¯•è¿›åº¦] æ‰€æœ‰ä¸»é¢˜å·²å®Œæˆ")
            else:
                # å»¶ä¼¸è¿½é—®ï¼Œä¿æŒå½“å‰ä¸»é¢˜
                print(f"[é¢è¯•è¿›åº¦] å»¶ä¼¸è¿½é—®ï¼Œç»§ç»­ä¸»é¢˜ï¼š{current_topic}")

            # ä¿å­˜æ›´æ–°åçš„è®¡åˆ’
            session.interview_plan = interview_plan
            flag_modified(session, "interview_plan")

            # å°†åé¦ˆå’Œé—®é¢˜ç»„åˆï¼ˆå¦‚æœæœ‰åé¦ˆçš„è¯ï¼‰
            if feedback:
                full_response = f"{feedback}\n\n{next_question}"
            else:
                full_response = next_question

            # è®°å½•ä¸‹ä¸€ä¸ªé—®é¢˜
            session.question_count += 1
            session.current_question = full_response

            # ç¡®å®šå½“å‰æ‰€åœ¨ä¸»é¢˜
            active_topic_index = interview_plan.get("current_topic_index", 0)
            active_topic = topics[active_topic_index] if active_topic_index < len(topics) else current_topic

            session.transcript.append({
                "role": "interviewer",
                "content": full_response,
                "timestamp": datetime.utcnow().isoformat(),
                "question_number": session.question_count,
                "feedback": feedback,  # å•ç‹¬ä¿å­˜åé¦ˆç”¨äºç»Ÿè®¡
                "topic": active_topic,  # ä¿å­˜å½“å‰ä¸»é¢˜
                "action": action  # ä¿å­˜åŠ¨ä½œç±»å‹
            })
            flag_modified(session, "transcript")

            db.commit()

            return AnswerResponse(
                next_question=full_response,
                instant_score=instant_score,
                hint=hint,
                is_finished=False
            )
        else:
            # é¢è¯•ç»“æŸ
            session.is_finished = True
            session.finished_at = datetime.utcnow()
            db.commit()

            # ç”ŸæˆæŠ¥å‘Š
            report = self.generate_report(request.session_id, db)

            return AnswerResponse(
                next_question=None,
                instant_score=None,
                hint="é¢è¯•å·²ç»“æŸï¼Œæ„Ÿè°¢æ‚¨çš„å‚ä¸ï¼",
                is_finished=True
            )

    def generate_report(self, session_id: str, db: Session) -> InterviewReportSchema:
        """ç”Ÿæˆé¢è¯•æŠ¥å‘Š"""
        # è·å–ä¼šè¯
        session = db.query(InterviewSession).filter(
            InterviewSession.session_id == session_id
        ).first()

        if not session:
            raise ValueError("ä¼šè¯ä¸å­˜åœ¨")

        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æŠ¥å‘Š
        existing_report = db.query(InterviewReport).filter(
            InterviewReport.session_id == session_id
        ).first()

        if existing_report:
            return InterviewReportSchema(
                session_id=existing_report.session_id,
                total_score=existing_report.total_score,
                technical_skill=existing_report.technical_skill,
                communication=existing_report.communication,
                logic_thinking=existing_report.logic_thinking,
                experience=existing_report.experience,
                suggestions=existing_report.suggestions,
                transcript=existing_report.transcript,
                created_at=existing_report.created_at
            )

        # ä½¿ç”¨å¤§æ¨¡å‹åˆ†æé¢è¯•è¡¨ç°
        system_prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„{session.position}é¢è¯•è¯„ä¼°ä¸“å®¶ã€‚
è¯·æ ¹æ®ä»¥ä¸‹é¢è¯•å¯¹è¯è®°å½•ï¼Œç”Ÿæˆè¯¦ç»†çš„é¢è¯•è¯„ä¼°æŠ¥å‘Šã€‚"""

        transcript_text = "\n\n".join([
            f"{'é¢è¯•å®˜' if item['role'] == 'interviewer' else 'å€™é€‰äºº'}: {item['content']}"
            for item in session.transcript
        ])

        messages = [{
            "role": "user",
            "content": f"""é¢è¯•è®°å½•ï¼š

{transcript_text}

è¯·å¯¹å€™é€‰äººçš„è¡¨ç°è¿›è¡Œå…¨é¢è¯„ä¼°ï¼Œå¹¶æŒ‰ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

{{
    "total_score": 85.5,
    "technical_skill": 88.0,
    "communication": 82.0,
    "logic_thinking": 86.0,
    "experience": 85.0,
    "suggestions": [
        "å»ºè®®1",
        "å»ºè®®2",
        "å»ºè®®3"
    ]
}}

è¯„åˆ†æ ‡å‡†ï¼ˆ0-100åˆ†ï¼‰ï¼š
- technical_skill: æŠ€æœ¯èƒ½åŠ›ï¼Œä¸“ä¸šçŸ¥è¯†æ·±åº¦å’Œå¹¿åº¦
- communication: è¡¨è¾¾èƒ½åŠ›ï¼Œé€»è¾‘æ¸…æ™°åº¦å’Œæ²Ÿé€šæ•ˆæœ
- logic_thinking: é€»è¾‘æ€ç»´ï¼Œé—®é¢˜åˆ†æå’Œè§£å†³èƒ½åŠ›
- experience: é¡¹ç›®ç»éªŒï¼Œå®è·µç»éªŒå’Œåº”ç”¨èƒ½åŠ›
- total_score: ç»¼åˆè¯„åˆ†

suggestionsè¦åŒ…å«3-5æ¡å…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚"""
        }]

        response_text = self._call_llm(messages, system=system_prompt, temperature=0.5)

        # è§£ææŠ¥å‘Š
        try:
            import re
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                report_data = json.loads(json_match.group())
            else:
                report_data = json.loads(response_text)
        except:
            # é»˜è®¤è¯„åˆ†
            report_data = {
                "total_score": 75.0,
                "technical_skill": 75.0,
                "communication": 75.0,
                "logic_thinking": 75.0,
                "experience": 75.0,
                "suggestions": ["ç»§ç»­åŠ å¼ºæŠ€æœ¯å­¦ä¹ ", "æå‡è¡¨è¾¾èƒ½åŠ›", "ç§¯ç´¯é¡¹ç›®ç»éªŒ"]
            }

        # ä¿å­˜æŠ¥å‘Š
        report = InterviewReport(
            session_id=session_id,
            user_id=session.user_id,
            total_score=report_data["total_score"],
            technical_skill=report_data["technical_skill"],
            communication=report_data["communication"],
            logic_thinking=report_data["logic_thinking"],
            experience=report_data["experience"],
            suggestions=report_data["suggestions"],
            transcript=session.transcript
        )
        db.add(report)
        db.commit()

        return InterviewReportSchema(
            session_id=session_id,
            total_score=report_data["total_score"],
            technical_skill=report_data["technical_skill"],
            communication=report_data["communication"],
            logic_thinking=report_data["logic_thinking"],
            experience=report_data["experience"],
            suggestions=report_data["suggestions"],
            transcript=session.transcript,
            created_at=report.created_at
        )
